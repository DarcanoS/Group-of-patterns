# Design Patterns - Ingestion Service

Este documento describe los patrones de diseÃ±o implementados en el servicio de ingestion de Air Quality Platform.

---

## ğŸ“ Patrones Implementados

### 1. Adapter Pattern (PatrÃ³n Adaptador)

**UbicaciÃ³n**: `app/providers/`

**PropÃ³sito**: Convertir la interfaz de diferentes fuentes de datos (archivos CSV, APIs externas) en una interfaz comÃºn que el servicio de ingestion pueda consumir de manera uniforme.

#### Estructura

```
app/providers/
â”œâ”€â”€ base_adapter.py              # Interface abstracta
â”œâ”€â”€ historical_csv_adapter.py    # Adapter concreto para CSV
â””â”€â”€ aqicn_adapter.py             # (Futuro) Adapter para AQICN API
```

#### Componentes

**1. Base Adapter (Interface)**

```python
# app/providers/base_adapter.py

class BaseExternalApiAdapter(ABC):
    """
    Adapter Pattern Implementation
    
    Interfaz base que define el contrato comÃºn para todos los adaptadores
    de fuentes de datos externas.
    """
    
    @abstractmethod
    def fetch_readings(self) -> List[NormalizedReading]:
        """
        Obtiene y normaliza lecturas desde la fuente de datos especÃ­fica.
        
        Returns:
            Lista de objetos NormalizedReading
        """
        pass
```

**2. Concrete Adapter - CSV**

```python
# app/providers/historical_csv_adapter.py

class HistoricalCsvAdapter(BaseExternalApiAdapter):
    """
    Adapter Pattern: CSV File Source
    
    Adapta archivos CSV histÃ³ricos al formato comÃºn NormalizedReading.
    """
    
    def __init__(
        self,
        csv_file_path: Path,
        station_metadata: StationMetadata,
        pollutant_mapping: Dict[str, Dict[str, str]]
    ):
        # ConfiguraciÃ³n especÃ­fica para CSV
        ...
    
    def fetch_readings(self) -> List[NormalizedReading]:
        # LÃ³gica especÃ­fica para leer CSV
        # 1. Lee archivo CSV con pandas
        # 2. Procesa cada fila
        # 3. Normaliza timestamps, pollutants, unidades
        # 4. Valida valores
        # 5. Estima AQI
        # 6. Retorna lista de NormalizedReading
        ...
```

**3. Target Format (DTO comÃºn)**

```python
# app/domain/dto.py

class NormalizedReading(BaseModel):
    """
    Formato comÃºn de salida para todos los adapters.
    
    Independiente de la fuente de datos original.
    """
    external_station_id: str
    station_name: Optional[str]
    latitude: Optional[float]
    longitude: Optional[float]
    city: Optional[str]
    country: Optional[str]
    pollutant_code: str
    unit: str
    value: float
    aqi: Optional[int]
    timestamp_utc: datetime
```

#### Diagrama de Clases

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BaseExternalApiAdapter (ABC)     â”‚
â”‚                                     â”‚
â”‚  + fetch_readings()                 â”‚
â”‚    â†’ List[NormalizedReading]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ implements
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HistoricalCSV    â”‚  â”‚  AqicnAdapter      â”‚
â”‚ Adapter          â”‚  â”‚  (futuro)          â”‚
â”‚                  â”‚  â”‚                    â”‚
â”‚ - csv_file_path  â”‚  â”‚ - api_token        â”‚
â”‚ - station_meta   â”‚  â”‚ - base_url         â”‚
â”‚                  â”‚  â”‚                    â”‚
â”‚ + fetch_readings â”‚  â”‚ + fetch_readings   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â”‚ produces             â”‚ produces
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Normalized    â”‚
            â”‚ Reading       â”‚
            â”‚ (DTO)         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Ventajas del PatrÃ³n

1. **Desacoplamiento**: El servicio de ingestion no necesita conocer los detalles de cada fuente de datos.

2. **Extensibilidad**: Agregar una nueva fuente de datos solo requiere:
   - Crear un nuevo adapter que implemente `BaseExternalApiAdapter`
   - No modificar el cÃ³digo existente (Open/Closed Principle)

3. **Uniformidad**: Todas las fuentes producen el mismo formato de salida (`NormalizedReading`).

4. **Testabilidad**: Cada adapter puede testearse de forma independiente.

#### Ejemplo de Uso

```python
# En app/services/ingestion_service.py

class IngestionService:
    def create_historical_adapters(self) -> List[BaseExternalApiAdapter]:
        adapters = []
        
        # Crear adapters CSV para cada estaciÃ³n
        for station_config in config['stations']:
            adapter = HistoricalCsvAdapter(
                csv_file_path=Path(station_config['csv_file']),
                station_metadata=StationMetadata(**station_config),
                pollutant_mapping=config['pollutant_mapping']
            )
            adapters.append(adapter)
        
        return adapters
    
    def run_historical_ingestion(self):
        # El servicio trabaja con la interfaz abstracta
        adapters = self.create_historical_adapters()
        
        for adapter in adapters:
            # Mismo cÃ³digo funciona para cualquier adapter
            readings = adapter.fetch_readings()
            self._persist_readings(readings)
```

#### Caso Real de Uso

**Problema Original**: 
- Datos histÃ³ricos en CSV con formato especÃ­fico
- Futuras fuentes: API AQICN, sensores IoT, otras APIs pÃºblicas
- Cada fuente tiene formato, unidades y nombres diferentes

**SoluciÃ³n con Adapter**:
```python
# CSV Adapter
csv_adapter = HistoricalCsvAdapter(...)
readings_csv = csv_adapter.fetch_readings()  # â†’ List[NormalizedReading]

# API Adapter (futuro)
api_adapter = AqicnAdapter(token="...")
readings_api = api_adapter.fetch_readings()  # â†’ List[NormalizedReading]

# El servicio procesa ambos de la misma forma
for reading in readings_csv + readings_api:
    persist_to_database(reading)
```

---

## ğŸ”„ Patrones Relacionados

### Repository Pattern (ImplÃ­cito)

Aunque no estÃ¡ explÃ­citamente nombrado, el servicio de ingestion implementa el patrÃ³n Repository al separar la lÃ³gica de acceso a datos:

```python
# app/services/ingestion_service.py

class IngestionService:
    """ActÃºa como un Repository para operaciones de ingestion"""
    
    def _get_or_create_station(self, reading: NormalizedReading) -> int:
        """Abstrae la lÃ³gica de acceso a Station"""
        ...
    
    def _get_pollutant_id(self, pollutant_code: str) -> Optional[int]:
        """Abstrae la lÃ³gica de acceso a Pollutant"""
        ...
    
    def _persist_readings(self, readings: List[NormalizedReading]):
        """Abstrae la persistencia de readings"""
        ...
```

**Beneficios**:
- LÃ³gica de BD centralizada
- FÃ¡cil testing con mocks
- Cache interno para performance

### Strategy Pattern (ImplÃ­cito en NormalizaciÃ³n)

La normalizaciÃ³n de datos usa diferentes estrategias segÃºn el tipo de pollutant:

```python
# app/domain/normalization.py

def estimate_aqi(pollutant_code: str, value: float) -> Optional[int]:
    """
    Strategy Pattern implÃ­cito: diferentes algoritmos segÃºn pollutant
    """
    if pollutant_code == "PM2.5":
        return calculate_aqi_pm25(value)
    elif pollutant_code == "PM10":
        return calculate_aqi_pm10(value)  # (futuro)
    # ... otras estrategias
```

---

## ğŸ“Š Data Transfer Object (DTO) Pattern

**UbicaciÃ³n**: `app/domain/dto.py`

El servicio usa DTOs (Pydantic models) para transferir datos entre capas:

```python
class NormalizedReading(BaseModel):
    """
    DTO para lecturas normalizadas.
    
    Ventajas:
    - ValidaciÃ³n automÃ¡tica (Pydantic)
    - Type safety
    - SerializaciÃ³n/DeserializaciÃ³n
    - DocumentaciÃ³n clara
    """
    pollutant_code: str = Field(...)
    value: float = Field(ge=0)  # ValidaciÃ³n: >= 0
    timestamp_utc: datetime
    
    @field_validator('pollutant_code')
    @classmethod
    def normalize_pollutant_code(cls, v: str) -> str:
        return v.strip().upper()
```

**SeparaciÃ³n de capas**:
```
CSV Row â†’ NormalizedReading (DTO) â†’ AirQualityReading (ORM)
  â†‘                  â†‘                        â†‘
Fuente         Domain Layer              Database Layer
```

---

## ğŸ—ï¸ Arquitectura en Capas

El servicio sigue una arquitectura limpia por capas:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Presentation Layer              â”‚
â”‚         (app/main.py - CLI)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Service Layer                   â”‚
â”‚    (app/services/ingestion_service.py)  â”‚
â”‚    - Orchestration                      â”‚
â”‚    - Business logic                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Providersâ”‚ â”‚ Domain  â”‚ â”‚ DB Layer   â”‚
â”‚(Adapters)â”‚ â”‚ (DTOs,  â”‚ â”‚ (Models,   â”‚
â”‚          â”‚ â”‚  Norm.) â”‚ â”‚  Session)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ventajas**:
- Cada capa tiene responsabilidades claras
- FÃ¡cil testing individual
- Cambios en una capa no afectan otras

---

## ğŸ¯ Principios SOLID Aplicados

### Single Responsibility Principle (SRP)
- `HistoricalCsvAdapter`: Solo lee y normaliza CSV
- `IngestionService`: Solo orquesta la ingestion
- `normalization.py`: Solo normaliza datos

### Open/Closed Principle (OCP)
- Agregar nuevo adapter no requiere modificar cÃ³digo existente
- Solo extender `BaseExternalApiAdapter`

### Liskov Substitution Principle (LSP)
- Cualquier `BaseExternalApiAdapter` puede usarse donde se espera la interfaz base
- `HistoricalCsvAdapter` y `AqicnAdapter` son intercambiables

### Interface Segregation Principle (ISP)
- `BaseExternalApiAdapter` define solo el mÃ©todo necesario: `fetch_readings()`
- No fuerza implementaciones innecesarias

### Dependency Inversion Principle (DIP)
- `IngestionService` depende de la abstracciÃ³n `BaseExternalApiAdapter`
- No depende de implementaciones concretas (CSV, API)

---

## ğŸ“ Ejemplo Completo: Agregar Nueva Fuente de Datos

### Paso 1: Crear Nuevo Adapter

```python
# app/providers/iot_sensor_adapter.py

from app.providers.base_adapter import BaseExternalApiAdapter
from app.domain.dto import NormalizedReading

class IoTSensorAdapter(BaseExternalApiAdapter):
    """
    Adapter Pattern: IoT Sensor API
    
    Adapta datos de sensores IoT al formato comÃºn.
    """
    
    def __init__(self, mqtt_broker: str, topic: str):
        self.mqtt_broker = mqtt_broker
        self.topic = topic
    
    def fetch_readings(self) -> List[NormalizedReading]:
        # 1. Conectar a MQTT broker
        client = mqtt.Client()
        client.connect(self.mqtt_broker)
        
        # 2. Suscribirse al topic
        messages = client.subscribe(self.topic)
        
        # 3. Parsear mensajes JSON
        readings = []
        for msg in messages:
            data = json.loads(msg.payload)
            
            # 4. Normalizar a NormalizedReading
            reading = NormalizedReading(
                external_station_id=data['sensor_id'],
                pollutant_code=standardize_pollutant_name(data['pollutant']),
                value=float(data['value']),
                timestamp_utc=normalize_timestamp(data['timestamp']),
                # ... otros campos
            )
            readings.append(reading)
        
        return readings
```

### Paso 2: Registrar en el Servicio

```python
# app/services/ingestion_service.py

def create_iot_adapters(self) -> List[BaseExternalApiAdapter]:
    adapters = []
    
    for sensor_config in config['iot_sensors']:
        adapter = IoTSensorAdapter(
            mqtt_broker=sensor_config['broker'],
            topic=sensor_config['topic']
        )
        adapters.append(adapter)
    
    return adapters
```

### Paso 3: Usar (sin cambios en cÃ³digo existente)

```python
# El mismo cÃ³digo funciona para cualquier adapter
adapters = create_historical_adapters() + create_iot_adapters()

for adapter in adapters:
    readings = adapter.fetch_readings()  # âœ“ Mismo mÃ©todo
    persist_readings(readings)            # âœ“ Mismo procesamiento
```

---

## ğŸ§ª Testing de Patrones

### Test del Adapter Pattern

```python
import pytest
from app.providers.historical_csv_adapter import HistoricalCsvAdapter

def test_csv_adapter_normalizes_data():
    """Verifica que el CSV adapter normaliza correctamente"""
    adapter = HistoricalCsvAdapter(
        csv_file_path=Path("test_data.csv"),
        station_metadata=mock_station,
        pollutant_mapping=mock_pollutants
    )
    
    readings = adapter.fetch_readings()
    
    # Assertions
    assert len(readings) > 0
    assert all(isinstance(r, NormalizedReading) for r in readings)
    assert all(r.pollutant_code in ['PM2.5', 'PM10', 'O3'] for r in readings)
    assert all(r.timestamp_utc.tzinfo is not None for r in readings)  # UTC

def test_adapters_are_interchangeable():
    """Verifica que todos los adapters cumplen el contrato"""
    csv_adapter = HistoricalCsvAdapter(...)
    api_adapter = MockApiAdapter(...)
    
    def process_adapter(adapter: BaseExternalApiAdapter):
        readings = adapter.fetch_readings()
        return len(readings)
    
    # Ambos funcionan con la misma funciÃ³n
    assert process_adapter(csv_adapter) > 0
    assert process_adapter(api_adapter) > 0
```

---

## ğŸ“š Referencias

### Adapter Pattern
- **Gang of Four**: "Design Patterns: Elements of Reusable Object-Oriented Software"
- **Refactoring Guru**: https://refactoring.guru/design-patterns/adapter
- **Use Case**: Integrar mÃºltiples fuentes de datos con interfaces incompatibles

### Repository Pattern
- **Martin Fowler**: "Patterns of Enterprise Application Architecture"
- **Use Case**: Separar lÃ³gica de negocio de acceso a datos

### DTO Pattern
- **Martin Fowler**: "Patterns of Enterprise Application Architecture"
- **Pydantic Docs**: https://docs.pydantic.dev/
- **Use Case**: Transferir datos entre capas manteniendo type safety

---

## ğŸ”® EvoluciÃ³n Futura

### Patrones Candidatos para Implementar

#### 1. Factory Pattern
Para crear adapters dinÃ¡micamente:

```python
class AdapterFactory:
    @staticmethod
    def create_adapter(source_type: str, config: dict) -> BaseExternalApiAdapter:
        if source_type == "csv":
            return HistoricalCsvAdapter(**config)
        elif source_type == "aqicn":
            return AqicnAdapter(**config)
        elif source_type == "iot":
            return IoTSensorAdapter(**config)
        else:
            raise ValueError(f"Unknown source type: {source_type}")
```

#### 2. Observer Pattern
Para notificaciones cuando llegan nuevos datos:

```python
class IngestionObserver(ABC):
    @abstractmethod
    def on_readings_ingested(self, count: int):
        pass

class MetricsObserver(IngestionObserver):
    def on_readings_ingested(self, count: int):
        send_to_prometheus({"readings_ingested": count})
```

#### 3. Chain of Responsibility
Para procesamiento de validaciÃ³n en cadena:

```python
class ValidationHandler(ABC):
    def __init__(self, next_handler=None):
        self.next = next_handler
    
    @abstractmethod
    def validate(self, reading: NormalizedReading) -> bool:
        pass

class RangeValidator(ValidationHandler):
    def validate(self, reading):
        if not is_valid_concentration(reading.value, reading.pollutant_code):
            return False
        return self.next.validate(reading) if self.next else True
```

---

## ğŸ“Š Resumen

| PatrÃ³n | UbicaciÃ³n | Estado | PropÃ³sito |
|--------|-----------|--------|-----------|
| **Adapter** | `app/providers/` | âœ… Implementado | Unificar fuentes de datos |
| **DTO** | `app/domain/dto.py` | âœ… Implementado | Transferencia entre capas |
| **Repository** | `app/services/` | âœ… ImplÃ­cito | Acceso a datos |
| **Strategy** | `app/domain/normalization.py` | âœ… ImplÃ­cito | Algoritmos de normalizaciÃ³n |
| **Factory** | - | ğŸ“‹ Futuro | CreaciÃ³n dinÃ¡mica de adapters |
| **Observer** | - | ğŸ“‹ Futuro | Notificaciones de eventos |

---

**Ãšltima actualizaciÃ³n**: 26 de noviembre de 2025  
**Autor**: Air Quality Platform Team  
**VersiÃ³n**: 1.0
