# Air Quality Platform - Ingestion Service

Servicio de ingestion de datos para la plataforma Air Quality Platform.

## ğŸ“‹ DescripciÃ³n

Este servicio implementa:

1. **Ingestion HistÃ³rica** (one-time, repeatable):
   - Lee datos de archivos CSV histÃ³ricos
   - Lee metadata de estaciones desde archivos GeoJSON
   - Normaliza y valida los datos
   - Inserta en PostgreSQL

2. **Ingestion en Tiempo Real** (futuro):
   - Consume API de AQICN
   - EjecuciÃ³n periÃ³dica configurable
   - (Pendiente de implementaciÃ³n)

## ğŸ¨ Patrones de DiseÃ±o

### Adapter Pattern â­

El patrÃ³n **Adapter** estÃ¡ implementado en `app/providers/`:

- **`BaseExternalApiAdapter`**: Interfaz base para adaptadores
- **`HistoricalCsvAdapter`**: Adapta archivos CSV al formato comÃºn
- **`AqicnAdapter`**: (Futuro) Adapta API de AQICN

Esto permite:
- Unificar diferentes fuentes de datos (CSV, APIs)
- Desacoplar la lÃ³gica de ingestion de las fuentes especÃ­ficas
- Facilitar la adiciÃ³n de nuevas fuentes sin modificar el core

**ğŸ“š DocumentaciÃ³n Completa**:
- **[DESIGN_PATTERNS.md](./DESIGN_PATTERNS.md)**: TeorÃ­a, ejemplos de cÃ³digo, referencias
- **[ARCHITECTURE.md](./ARCHITECTURE.md)**: Diagramas visuales, flujos de datos, casos de uso

## ğŸ“ Estructura

```
ingestion/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py              # ConfiguraciÃ³n (env vars)
â”‚   â”œâ”€â”€ logging_config.py      # Logging setup
â”‚   â”œâ”€â”€ main.py                # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ session.py         # DB connection
â”‚   â”‚   â””â”€â”€ models.py          # ORM models
â”‚   â”‚
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ dto.py             # Pydantic DTOs
â”‚   â”‚   â””â”€â”€ normalization.py  # Data normalization
â”‚   â”‚
â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”œâ”€â”€ base_adapter.py           # Adapter pattern base
â”‚   â”‚   â””â”€â”€ historical_csv_adapter.py # CSV adapter
â”‚   â”‚
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ ingestion_service.py      # Orchestration
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ station_mapping.yaml   # Mapeo CSV â†’ Station metadata
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ .env.example
```

## âš™ï¸ ConfiguraciÃ³n

### 1. Variables de Entorno

Copia `.env.example` a `.env` y configura:

```bash
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/air_quality_db

# Paths
HISTORICAL_DATA_PATH=../data_air
STATION_MAPPING_PATH=data/station_mapping.yaml

# Logging
INGESTION_LOG_LEVEL=INFO
```

### 2. Station Mapping

Edita `data/station_mapping.yaml` para mapear archivos CSV a estaciones:

```yaml
stations:
  - csv_file: "carvajal,-bogota, colombia-air-quality.csv"
    station_name: "Carvajal"
    latitude: 4.614728
    longitude: -74.139465
    city: "BogotÃ¡"
    country: "Colombia"
```

## ğŸš€ Uso

### InstalaciÃ³n Local

```bash
# Instalar dependencias
pip install -r requirements.txt

# Configurar .env
cp .env.example .env
# Editar .env con tus credenciales

# Ejecutar ingestion histÃ³rica
python -m app.main --mode historical

# Ver ayuda
python -m app.main --help
```

### Docker

```bash
# Build image
docker build -t air-quality-ingestion .

# Run historical ingestion
docker run --rm \
  --env-file .env \
  -v $(pwd)/../data_air:/data_air \
  air-quality-ingestion
```

## ğŸ“Š Datos de Entrada

### CSV Files (`data_air/`)

Formato esperado:

```csv
date, pm25, pm10, o3, no2, so2, co
2019/10/2, 116, 47, 9, 14, 1, 11
2019/10/3, 115, 38, 3, 12, 1, 12
```

- **Columnas**: date, pm25, pm10, o3, no2, so2, co
- **Fechas**: formato `YYYY/M/D`
- **Valores vacÃ­os**: se omiten (missing data)

### GeoJSON Files

Metadata de estaciones en formato GeoJSON:

```json
{
  "type": "FeatureCollection",
  "features": [{
    "properties": {
      "estacion": "Centro de Alto Rendimiento",
      "codestac": "5",
      "altura": 2577
    }
  }]
}
```

## ğŸ”§ Desarrollo

### Agregar Nueva Fuente de Datos

1. Crear nuevo adapter en `app/providers/`:

```python
from app.providers.base_adapter import BaseExternalApiAdapter

class MyNewAdapter(BaseExternalApiAdapter):
    def fetch_readings(self) -> List[NormalizedReading]:
        # Implementar lÃ³gica
        pass
```

2. Registrar en el servicio de ingestion

3. Configurar en `.env` si es necesario

### Tests

```bash
# Ejecutar tests (cuando estÃ©n implementados)
pytest

# Test con log detallado
python -m app.main --mode historical --log-level DEBUG
```

## ğŸ“ Notas de ImplementaciÃ³n

### NormalizaciÃ³n de Datos

- **Timestamps**: Convertidos a UTC
- **Pollutants**: Nombres estandarizados (PM2.5, PM10, O3, etc.)
- **Units**: Âµg/mÂ³ para PM, ppb para gases, ppm para CO
- **AQI**: Estimado usando fÃ³rmula simplificada EPA (solo PM2.5 por ahora)

### Manejo de Duplicados

El servicio detecta y omite lecturas duplicadas basÃ¡ndose en:
- `station_id`
- `pollutant_id`
- `datetime`

Esto permite re-ejecutar la ingestion histÃ³rica de forma segura.

### Base de Datos

Requiere que las tablas ya estÃ©n creadas:
- `station`
- `pollutant` (con datos seed)
- `air_quality_reading`

El servicio **no** crea tablas ni datos de catÃ¡logo.

## ğŸ”® Trabajo Futuro

- [ ] Implementar `AqicnAdapter` para API en tiempo real
- [ ] Agregar scheduler para ingestion periÃ³dica
- [ ] Implementar `AggregationService` para stats diarias
- [ ] Agregar tests unitarios
- [ ] Mejorar cÃ¡lculo de AQI (mÃ¡s pollutants)
- [ ] ValidaciÃ³n de coordenadas GeoJSON

## ğŸ“š Referencias

- [AQICN API Documentation](https://aqicn.org/api/)
- [EPA AQI Calculator](https://www.airnow.gov/aqi/aqi-calculator/)
- [Adapter Pattern](https://refactoring.guru/design-patterns/adapter)
